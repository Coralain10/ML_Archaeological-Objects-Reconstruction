{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzkOpxE9YyEUVXbopCFp7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coralain10/ML_Archaeological-Objects-Reconstruction/blob/main/FinalResults.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fm7okTdwCH1j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data"
      ],
      "metadata": {
        "id": "LMPoQuv8LdZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Coralain10/ML_Archaeological-Objects-Reconstruction/blob/main/data/FullAndFracture.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqRi_uQMa7yq",
        "outputId": "09a2fa39-a6b4-4bcd-bd4c-b722d021cf37"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-25 23:06:51--  https://github.com/Coralain10/ML_Archaeological-Objects-Reconstruction/blob/main/data/FullAndFracture.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘FullAndFracture.zip.1’\n",
            "\n",
            "FullAndFracture.zip     [ <=>                ] 143.71K   781KB/s    in 0.2s    \n",
            "\n",
            "2022-11-25 23:06:51 (781 KB/s) - ‘FullAndFracture.zip.1’ saved [147158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip FullAndFracture.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owo9ra5VBezL",
        "outputId": "a1f17383-67c0-4fde-dce0-a39c6f35ee49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  FullAndFracture.zip\n",
            "  inflating: FullAndFracture.npy     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('FullAndFracture.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "FOS1_5gGa8z9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype = np.int32)"
      ],
      "metadata": {
        "id": "qoICYp9Kk68q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[1]\n",
        "Y = data[0]"
      ],
      "metadata": {
        "id": "E7Sf7KJ0bL3I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lx = X.shape[0]\n",
        "ly = Y.shape[0]"
      ],
      "metadata": {
        "id": "4DGJTwPMeCJ3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(X)\n",
        "Y = list(Y)"
      ],
      "metadata": {
        "id": "q1DG_stUek3X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flattening each chair\n",
        "for i in range(lx):\n",
        "  X[i] = X[i].flatten()\n",
        "for i in range(ly):\n",
        "  Y[i] = Y[i].flatten()"
      ],
      "metadata": {
        "id": "hU3-lPj2eMo7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "VkMxMHoLfCjL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = 7112 * 0.7 // 1\n",
        "train = int(train)"
      ],
      "metadata": {
        "id": "jmWEUl0NDMAv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = X[:train], X[train:], Y[:train], Y[train:]"
      ],
      "metadata": {
        "id": "mtGa_9NUbOn3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZLroTS_d7o1",
        "outputId": "1cfd64d8-1086-4f45-aedd-5ac139d187e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4978, 32768) (4978, 32768)\n",
            "(2134, 32768) (2134, 32768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing, traing and saving the model"
      ],
      "metadata": {
        "id": "ey9y-Tl3LTnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(32768,)))\n",
        "model.add(tf.keras.layers.Dense(768, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(768, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(32768))\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "         loss = 'mean_squared_error',\n",
        "         metrics = ['mse'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UTjrcUKwzqg",
        "outputId": "6023a241-5ddf-4cb1-aa48-649ea3309a78"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "156/156 [==============================] - 84s 533ms/step - loss: 0.0357 - mse: 0.0357\n",
            "Epoch 2/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0223 - mse: 0.0223\n",
            "Epoch 3/200\n",
            "156/156 [==============================] - 83s 532ms/step - loss: 0.0160 - mse: 0.0160\n",
            "Epoch 4/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0122 - mse: 0.0122\n",
            "Epoch 5/200\n",
            "156/156 [==============================] - 83s 535ms/step - loss: 0.0101 - mse: 0.0101\n",
            "Epoch 6/200\n",
            "156/156 [==============================] - 83s 530ms/step - loss: 0.0085 - mse: 0.0085\n",
            "Epoch 7/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0078 - mse: 0.0078\n",
            "Epoch 8/200\n",
            "156/156 [==============================] - 83s 531ms/step - loss: 0.0074 - mse: 0.0074\n",
            "Epoch 9/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0071 - mse: 0.0071\n",
            "Epoch 10/200\n",
            "156/156 [==============================] - 83s 530ms/step - loss: 0.0069 - mse: 0.0069\n",
            "Epoch 11/200\n",
            "156/156 [==============================] - 83s 531ms/step - loss: 0.0066 - mse: 0.0066\n",
            "Epoch 12/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0066 - mse: 0.0066\n",
            "Epoch 13/200\n",
            "156/156 [==============================] - 84s 537ms/step - loss: 0.0063 - mse: 0.0063\n",
            "Epoch 14/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0059 - mse: 0.0059\n",
            "Epoch 15/200\n",
            "156/156 [==============================] - 83s 529ms/step - loss: 0.0055 - mse: 0.0055\n",
            "Epoch 16/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0053 - mse: 0.0053\n",
            "Epoch 17/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0052 - mse: 0.0052\n",
            "Epoch 18/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0049 - mse: 0.0049\n",
            "Epoch 19/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 20/200\n",
            "156/156 [==============================] - 83s 529ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 21/200\n",
            "156/156 [==============================] - 83s 530ms/step - loss: 0.0051 - mse: 0.0051\n",
            "Epoch 22/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0049 - mse: 0.0049\n",
            "Epoch 23/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0045 - mse: 0.0045\n",
            "Epoch 24/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0044 - mse: 0.0044\n",
            "Epoch 25/200\n",
            "156/156 [==============================] - 84s 538ms/step - loss: 0.0043 - mse: 0.0043\n",
            "Epoch 26/200\n",
            "156/156 [==============================] - 83s 534ms/step - loss: 0.0045 - mse: 0.0045\n",
            "Epoch 27/200\n",
            "156/156 [==============================] - 83s 534ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 28/200\n",
            "156/156 [==============================] - 84s 538ms/step - loss: 0.0046 - mse: 0.0046\n",
            "Epoch 29/200\n",
            "156/156 [==============================] - 84s 538ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 30/200\n",
            "156/156 [==============================] - 84s 537ms/step - loss: 0.0041 - mse: 0.0041\n",
            "Epoch 31/200\n",
            "156/156 [==============================] - 84s 538ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 32/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0042 - mse: 0.0042\n",
            "Epoch 33/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 34/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 35/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 36/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0041 - mse: 0.0041\n",
            "Epoch 37/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 38/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 39/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 40/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0039 - mse: 0.0039\n",
            "Epoch 41/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 42/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 43/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 44/200\n",
            "156/156 [==============================] - 82s 529ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 45/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 46/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 47/200\n",
            "156/156 [==============================] - 83s 529ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 48/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 49/200\n",
            "156/156 [==============================] - 83s 530ms/step - loss: 0.0043 - mse: 0.0043\n",
            "Epoch 50/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0043 - mse: 0.0043\n",
            "Epoch 51/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 52/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0035 - mse: 0.0035\n",
            "Epoch 53/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 54/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 55/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 56/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 57/200\n",
            "156/156 [==============================] - 83s 532ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 58/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 59/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 60/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 61/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 62/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 63/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 64/200\n",
            "156/156 [==============================] - 82s 529ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 65/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 66/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 67/200\n",
            "156/156 [==============================] - 83s 530ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 68/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 69/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 70/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 71/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 72/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 73/200\n",
            "156/156 [==============================] - 82s 529ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 74/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 75/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 76/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 77/200\n",
            "156/156 [==============================] - 82s 523ms/step - loss: 0.0065 - mse: 0.0065\n",
            "Epoch 78/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0048 - mse: 0.0048\n",
            "Epoch 79/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 80/200\n",
            "156/156 [==============================] - 82s 522ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 81/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 82/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 83/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 84/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 85/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 86/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 87/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 88/200\n",
            "156/156 [==============================] - 83s 529ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 89/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 90/200\n",
            "156/156 [==============================] - 83s 534ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 91/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 92/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 93/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 94/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 95/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 96/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 97/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 98/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 99/200\n",
            "156/156 [==============================] - 82s 523ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 100/200\n",
            "156/156 [==============================] - 82s 523ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 101/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 102/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 103/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 104/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 105/200\n",
            "156/156 [==============================] - 81s 523ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 106/200\n",
            "156/156 [==============================] - 81s 522ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 107/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0035 - mse: 0.0035\n",
            "Epoch 108/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 109/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 110/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 111/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 112/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 113/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 114/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 115/200\n",
            "156/156 [==============================] - 82s 523ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 116/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 117/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 118/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 119/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 120/200\n",
            "156/156 [==============================] - 80s 516ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 121/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 122/200\n",
            "156/156 [==============================] - 82s 527ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 123/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 124/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 125/200\n",
            "156/156 [==============================] - 80s 516ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 126/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 127/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 128/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 129/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 130/200\n",
            "156/156 [==============================] - 82s 526ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 131/200\n",
            "156/156 [==============================] - 82s 528ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 132/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 133/200\n",
            "156/156 [==============================] - 82s 525ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 134/200\n",
            "156/156 [==============================] - 82s 524ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 135/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 136/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 137/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 138/200\n",
            "156/156 [==============================] - 80s 516ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 139/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 140/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 141/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 142/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 143/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 144/200\n",
            "156/156 [==============================] - 81s 516ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 145/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 146/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 147/200\n",
            "156/156 [==============================] - 79s 509ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 148/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 149/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 150/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 151/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 152/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 153/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 154/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 155/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 156/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 157/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 158/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 159/200\n",
            "156/156 [==============================] - 79s 508ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 160/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 161/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 162/200\n",
            "156/156 [==============================] - 79s 509ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 163/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 164/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 165/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 166/200\n",
            "156/156 [==============================] - 81s 519ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 167/200\n",
            "156/156 [==============================] - 81s 521ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 168/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 169/200\n",
            "156/156 [==============================] - 80s 516ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 170/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 171/200\n",
            "156/156 [==============================] - 80s 511ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 172/200\n",
            "156/156 [==============================] - 80s 511ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 173/200\n",
            "156/156 [==============================] - 79s 507ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 174/200\n",
            "156/156 [==============================] - 81s 516ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 175/200\n",
            "156/156 [==============================] - 80s 510ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 176/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 177/200\n",
            "156/156 [==============================] - 81s 516ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 178/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 179/200\n",
            "156/156 [==============================] - 80s 516ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 180/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 181/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 182/200\n",
            "156/156 [==============================] - 79s 507ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 183/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 184/200\n",
            "156/156 [==============================] - 79s 507ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 185/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 186/200\n",
            "156/156 [==============================] - 81s 518ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 187/200\n",
            "156/156 [==============================] - 80s 511ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 188/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 189/200\n",
            "156/156 [==============================] - 81s 516ms/step - loss: 0.0023 - mse: 0.0023\n",
            "Epoch 190/200\n",
            "156/156 [==============================] - 81s 517ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 191/200\n",
            "156/156 [==============================] - 80s 510ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 192/200\n",
            "156/156 [==============================] - 81s 520ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 193/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 194/200\n",
            "156/156 [==============================] - 80s 512ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 195/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 196/200\n",
            "156/156 [==============================] - 80s 511ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 197/200\n",
            "156/156 [==============================] - 80s 515ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 198/200\n",
            "156/156 [==============================] - 80s 513ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 199/200\n",
            "156/156 [==============================] - 80s 514ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 200/200\n",
            "156/156 [==============================] - 79s 508ms/step - loss: 0.0031 - mse: 0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0eb2946190>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('FinalModel')"
      ],
      "metadata": {
        "id": "mZHYejbBC6pH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/FinalModel.zip /content/FinalModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65fmRD6MDBm0",
        "outputId": "63430d9a-4478-4c57-840b-dd862f53fa28"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/FinalModel/ (stored 0%)\n",
            "  adding: content/FinalModel/keras_metadata.pb (deflated 87%)\n",
            "  adding: content/FinalModel/saved_model.pb (deflated 88%)\n",
            "  adding: content/FinalModel/assets/ (stored 0%)\n",
            "  adding: content/FinalModel/variables/ (stored 0%)\n",
            "  adding: content/FinalModel/variables/variables.index (deflated 63%)\n",
            "  adding: content/FinalModel/variables/variables.data-00000-of-00001 (deflated 24%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the predictions"
      ],
      "metadata": {
        "id": "fqfBZ2weLO6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(x_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apDSp-MdbZRh",
        "outputId": "bdeae048-92f1-4a24-9b83-3b856223c4c9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 6s 92ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = prediction.round()\n",
        "prediction = np.array(prediction, dtype=np.int32)"
      ],
      "metadata": {
        "id": "X8rrV0XiC3J7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ploting Functions"
      ],
      "metadata": {
        "id": "lToVsigMLBZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot3d(verts, s=10, c=(105,127,155), show_grid=False):\n",
        "    x, y, z = zip(*verts)\n",
        "    color = f'rgb({c[0]}, {c[1]}, {c[2]})'\n",
        "    trace = go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=s,\n",
        "            color=color,\n",
        "            line=dict(\n",
        "                color='rgba(217, 217, 217, 0.14)',\n",
        "                width=0.5\n",
        "            ),\n",
        "            opacity=1\n",
        "        )\n",
        "    )\n",
        "    data = [trace]\n",
        "    layout = go.Layout(\n",
        "        margin=dict(l=0, r=0, b=0, t=0),\n",
        "        scene = go.Scene(\n",
        "            xaxis=dict(visible=show_grid),\n",
        "            yaxis=dict(visible=show_grid),\n",
        "            zaxis=dict(visible=show_grid)\n",
        "        )\n",
        "    )\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    iplot(fig)\n",
        "    \n",
        "def point_cloud_to_volume(points, vsize, radius=1.0):\n",
        "    vol = np.zeros((vsize,vsize,vsize), dtype=np.bool)\n",
        "    voxel = 2*radius/float(vsize)\n",
        "    locations = (points + radius)/voxel\n",
        "    locations = locations.astype(int)\n",
        "    vol[locations[:,0],locations[:,1],locations[:,2]] = 1.0\n",
        "    \n",
        "    return vol\n",
        "    \n",
        "def volume_to_point_cloud(vol):\n",
        "    \"\"\" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n",
        "        return Nx3 numpy array.\n",
        "    \"\"\"\n",
        "    vsize = vol.shape[0]\n",
        "    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n",
        "    points = []\n",
        "    for a in range(vsize):\n",
        "        for b in range(vsize):\n",
        "            for c in range(vsize):\n",
        "                if vol[a,b,c] == 1:\n",
        "                    points.append(np.array([a,b,c]))\n",
        "    if len(points) == 0:\n",
        "        return np.zeros((0,3))\n",
        "    points = np.vstack(points)\n",
        "    \n",
        "    return points\n",
        "\n",
        "def auto_pcl_to_volume(points, vsize):\n",
        "\tdata_min = np.min(points)\n",
        "\tdata_max = np.max(points)\n",
        "\tradius = max(abs(data_min), data_max)\n",
        "\tradius = math.ceil(radius*100) / 100\n",
        "\tvol = point_cloud_to_volume(points, vsize, radius)\n",
        "\n",
        "\treturn vol\n",
        "\n",
        "def plot_vol(vol, s=10, c=(105,127,155), show_grid=False):\n",
        "    if vol.dtype != np.bool:\n",
        "        vol = vol > 0\n",
        "\n",
        "    pc = volume_to_point_cloud(vol)\n",
        "    plot3d(pc, s, c, show_grid)\n",
        "\n",
        "def plot_reconstruction(vol1, vol2, s=10,\n",
        "                        c2=(105,128,155), c1=(182,49,62), show_grid=False):\n",
        "    if vol1.dtype != np.bool:\n",
        "        vol1 = vol1 > 0\n",
        "    if vol2.dtype != np.bool:\n",
        "        vol2 = vol2 > 0\n",
        "        \n",
        "    color1 = f'rgb({c1[0]}, {c1[1]}, {c1[2]})'\n",
        "    color2 = f'rgb({c2[0]}, {c2[1]}, {c2[2]})'\n",
        "    vol2 = np.logical_xor(vol2, vol1)\n",
        "    pc1 = volume_to_point_cloud(vol1)\n",
        "    pc2 = volume_to_point_cloud(vol2)\n",
        "    x1, y1, z1 = zip(*pc1)\n",
        "    x2, y2, z2 = zip(*pc2)\n",
        "    trace1 = go.Scatter3d(\n",
        "        x=x1, y=y1, z=z1,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=s,\n",
        "            color=color1,\n",
        "            line=dict(\n",
        "                color='rgba(217, 217, 217, 0.14)',\n",
        "                width=0.5\n",
        "            ),\n",
        "            opacity=1\n",
        "        )\n",
        "    )\n",
        "    trace2 = go.Scatter3d(\n",
        "        x=x2, y=y2, z=z2,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=s,\n",
        "            color=color2,\n",
        "            line=dict(\n",
        "                color='rgba(217, 217, 217, 0.14)',\n",
        "                width=0.5\n",
        "            ),\n",
        "            opacity=1\n",
        "        )\n",
        "    )\n",
        "    data = [trace1, trace2]\n",
        "    layout = go.Layout(margin=dict(l=0, r=0, b=0, t=0), \n",
        "                       scene = go.Scene(\n",
        "                               xaxis=dict(visible=show_grid),\n",
        "                               yaxis=dict(visible=show_grid),\n",
        "                               zaxis=dict(visible=show_grid)),\n",
        "                       showlegend=False)\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    iplot(fig)"
      ],
      "metadata": {
        "id": "jXJ9_w2cqLYR"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ploting the results"
      ],
      "metadata": {
        "id": "zM5Qo538Iyox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "k = randint(0, 2133)\n",
        "plot_reconstruction((prediction[k] - x_val[k]).reshape(32,32,32), prediction[k].reshape(32,32,32), s = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "Gl6BA5U-HdJQ",
        "outputId": "0d76ce53-07d5-484f-d712-750b8b6ca69f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning:\n",
            "\n",
            "`np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning:\n",
            "\n",
            "`np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e42a59d3-11e0-429c-80a2-0c8766347276\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e42a59d3-11e0-429c-80a2-0c8766347276\")) {                    Plotly.newPlot(                        \"e42a59d3-11e0-429c-80a2-0c8766347276\",                        [{\"marker\":{\"color\":\"rgb(182, 49, 62)\",\"line\":{\"color\":\"rgba(217, 217, 217, 0.14)\",\"width\":0.5},\"opacity\":1,\"size\":10},\"mode\":\"markers\",\"x\":[19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,26,26,26,26,26,26],\"y\":[21,21,21,21,22,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,25,25,25,25,21,21,21,22,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,25,25,25,25,22,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,25,25,25,25,22,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,25,25,25,25,22,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,25,25,25,25,17,18,19,20,21,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,25,25,25,25,17,18,19,20,21,22,23,24,17,18,19,20,21,22],\"z\":[16,17,18,19,17,18,19,20,21,22,23,24,25,24,25,16,17,18,19,20,21,22,22,23,24,25,16,17,18,16,17,18,19,20,21,22,23,24,24,25,16,17,18,19,20,21,22,22,23,24,25,16,17,18,19,20,21,22,23,24,24,25,16,17,18,19,20,21,22,22,23,24,25,16,17,18,19,20,21,22,23,24,24,25,16,17,18,19,20,21,22,22,23,24,25,16,17,18,19,20,21,22,23,24,24,25,16,17,18,19,20,21,22,22,23,24,25,19,19,19,19,19,16,17,18,19,20,21,22,23,24,16,17,18,19,20,21,22,23,24,25,16,17,18,19,20,21,22,23,24,25,22,23,24,25,19,19,19,19,19,19,19,19,19,19,19,19,19,19],\"type\":\"scatter3d\"},{\"marker\":{\"color\":\"rgb(105, 128, 155)\",\"line\":{\"color\":\"rgba(217, 217, 217, 0.14)\",\"width\":0.5},\"opacity\":1,\"size\":10},\"mode\":\"markers\",\"x\":[5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26],\"y\":[9,10,11,12,13,14,15,16,17,18,19,20,21,22,5,5,6,6,6,6,6,6,6,7,7,7,7,7,7,7,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,13,14,15,16,17,18,19,20,21,22,23,24,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,15,15,15,15,15,16,16,16,16,16,17,17,17,17,17,18,18,18,18,18,19,19,19,19,19,20,20,20,20,20,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,13,13,13,13,14,14,14,14,15,15,15,15,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,22,22,22,22,22,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,26,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,26,26,6,6,6,6,7,7,7,7,8,8,8,9,9,9,10,10,10,11,11,11,12,12,12,13,13,13,14,14,14,15,15,15,16,16,16,17,17,17,18,18,18,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,24,24,24,24,24,24,24,24,25,25,25,25,25,26,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,13,13,13,13,14,14,14,14,15,15,15,15,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,26,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,15,15,15,15,15,16,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,26,26,5,5,6,6,6,6,6,6,6,7,7,7,7,7,7,7,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,13,14,15,16,9,10,11,12,13,14,15,16],\"z\":[19,19,19,19,19,19,19,19,19,19,19,19,19,19,0,1,0,1,4,5,6,7,8,0,1,4,5,6,7,8,19,10,11,12,13,14,15,19,10,11,12,13,14,15,16,17,18,19,15,16,17,18,19,19,19,19,19,19,19,19,19,19,19,19,19,0,1,5,6,7,0,1,2,3,4,5,6,7,8,9,10,11,12,13,0,1,2,3,4,5,6,7,8,9,10,11,12,13,8,9,10,11,12,13,10,11,12,13,19,10,11,12,13,14,15,19,10,11,12,13,14,15,16,17,18,19,10,11,12,13,15,16,17,18,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,0,1,2,3,4,22,23,24,25,26,27,28,29,30,29,30,5,6,7,2,3,4,5,6,7,8,9,10,11,12,13,2,3,4,5,6,7,8,9,10,11,12,13,14,8,9,10,11,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,3,4,5,6,7,8,9,10,12,24,25,26,27,28,29,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,0,1,2,3,4,22,23,24,25,26,27,28,29,30,30,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,10,12,24,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,22,23,24,25,26,27,28,29,30,30,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,10,12,24,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,30,31,29,30,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,10,12,24,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,30,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,10,11,12,13,14,17,18,19,20,21,22,23,24,25,10,12,24,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,10,11,12,13,19,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,20,10,11,12,13,19,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,20,10,11,12,13,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,20,10,11,12,13,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,20,10,11,12,13,19,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,16,17,18,19,10,11,12,13,19,20,21,22,23,24,25,10,12,25,26,27,28,29,10,11,12,13,14,15,16,17,18,19,20,21,22,29,30,31,22,23,24,25,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,10,11,12,13,14,10,12,26,27,28,29,10,11,12,13,14,15,29,30,31,26,27,28,29,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,14,15,10,11,12,13,14,15,10,12,26,27,28,29,10,11,12,13,14,15,29,30,31,26,27,28,29,30,31,29,30,31,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,10,11,12,13,14,15,10,12,26,27,28,29,10,11,12,13,14,15,29,30,31,26,27,28,29,30,31,29,30,10,11,12,13,10,12,13,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,14,10,12,13,14,10,12,13,10,11,12,13,14,15,10,12,26,27,28,29,10,11,12,13,14,15,29,30,26,27,28,29,30,30,5,6,7,2,3,4,5,6,7,8,9,10,11,12,13,2,3,4,5,6,7,8,9,10,11,12,13,14,8,9,10,11,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,14,10,12,13,10,11,12,13,14,15,3,4,5,6,7,8,9,10,12,26,27,28,29,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,29,30,0,1,2,3,4,26,27,28,29,30,30,0,1,5,6,7,0,1,2,3,4,5,6,7,8,9,10,11,12,13,0,1,2,3,4,5,6,7,8,9,10,11,12,13,8,9,10,11,12,13,10,11,12,13,19,10,11,12,13,14,15,19,10,11,12,13,14,15,16,17,18,19,10,11,12,13,15,16,17,18,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,19,10,11,12,13,10,11,12,13,10,11,12,13,10,11,12,13,10,11,12,13,10,11,12,13,14,15,3,4,5,6,7,8,9,10,11,12,13,14,15,26,27,28,29,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,26,27,28,29,30,0,1,2,3,4,26,27,28,29,30,29,30,0,1,0,1,4,5,6,7,8,0,1,4,5,6,7,8,19,10,11,12,13,14,15,19,10,11,12,13,14,15,16,17,18,19,15,16,17,18,19,19,19,19,19,19,19,19,19,19,19,19,19],\"type\":\"scatter3d\"}],                        {\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":0},\"scene\":{\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false},\"zaxis\":{\"visible\":false}},\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e42a59d3-11e0-429c-80a2-0c8766347276');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the results to be printed"
      ],
      "metadata": {
        "id": "L_q3Y7ScIQOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install voxelfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd9UZrvyH_DB",
        "outputId": "d60bed21-b3bb-4050-ddbd-b65b7e6427bb"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting voxelfuse\n",
            "  Downloading voxelfuse-1.2.8-py3-none-any.whl (63.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.0 MB 8.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyopengl>=3.1.5 in /usr/local/lib/python3.7/dist-packages (from voxelfuse) (3.1.6)\n",
            "Collecting py-vox-io>=0.1\n",
            "  Downloading py-vox-io-0.1.tar.gz (4.8 kB)\n",
            "Collecting quad-mesh-simplify>=1.1.4\n",
            "  Downloading quad_mesh_simplify-1.1.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 61.1 MB/s \n",
            "\u001b[?25hCollecting pyqtgraph>=0.12.1\n",
            "  Downloading pyqtgraph-0.12.4-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.7/dist-packages (from voxelfuse) (4.64.1)\n",
            "Collecting pyqt5>=5.15.4\n",
            "  Downloading PyQt5-5.15.7-cp37-abi3-manylinux1_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting k3d>=2.9.4\n",
            "  Downloading k3d-2.14.5-py2.py3-none-any.whl (15.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.1 MB 34.1 MB/s \n",
            "\u001b[?25hCollecting meshio>=4.4.3\n",
            "  Downloading meshio-5.3.4-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from voxelfuse) (1.7.3)\n",
            "Collecting PyMCubes>=0.1.2\n",
            "  Downloading PyMCubes-0.1.2-cp37-cp37m-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[K     |████████████████████████████████| 265 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.7/dist-packages (from voxelfuse) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.7/dist-packages (from voxelfuse) (0.56.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from k3d>=2.9.4->voxelfuse) (1.0.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from k3d>=2.9.4->voxelfuse) (7.7.1)\n",
            "Collecting traittypes\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from k3d>=2.9.4->voxelfuse) (5.1.1)\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 47.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from meshio>=4.4.3->voxelfuse) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->voxelfuse) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->voxelfuse) (0.39.1)\n",
            "Collecting PyQt5-Qt5>=5.15.0\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.11\n",
            "  Downloading PyQt5_sip-12.11.0-cp37-cp37m-manylinux1_x86_64.whl (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from quad-mesh-simplify>=1.1.4->voxelfuse) (0.29.32)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->meshio>=4.4.3->voxelfuse) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->meshio>=4.4.3->voxelfuse) (4.1.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->k3d>=2.9.4->voxelfuse) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->k3d>=2.9.4->voxelfuse) (3.0.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->k3d>=2.9.4->voxelfuse) (5.3.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->k3d>=2.9.4->voxelfuse) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->k3d>=2.9.4->voxelfuse) (3.6.1)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->k3d>=2.9.4->voxelfuse) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->k3d>=2.9.4->voxelfuse) (6.1.12)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (5.7.16)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.15.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (5.7.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (4.11.2)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (1.8.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (23.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->k3d>=2.9.4->voxelfuse) (2.8.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.19.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (5.10.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->k3d>=2.9.4->voxelfuse) (0.5.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: py-vox-io\n",
            "  Building wheel for py-vox-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-vox-io: filename=py_vox_io-0.1-py3-none-any.whl size=5719 sha256=9fcbad5f4d5ac9991b6b6ea5bd77539393963807f64b9cb935189d0354839899\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/81/5c/d22c041200951b072c78e0fe0257b8be428739cd0fdab38791\n",
            "Successfully built py-vox-io\n",
            "Installing collected packages: jedi, commonmark, traittypes, rich, PyQt5-sip, PyQt5-Qt5, quad-mesh-simplify, pyqtgraph, pyqt5, PyMCubes, py-vox-io, meshio, k3d, voxelfuse\n",
            "Successfully installed PyMCubes-0.1.2 PyQt5-Qt5-5.15.2 PyQt5-sip-12.11.0 commonmark-0.9.1 jedi-0.18.2 k3d-2.14.5 meshio-5.3.4 py-vox-io-0.1 pyqt5-5.15.7 pyqtgraph-0.12.4 quad-mesh-simplify-1.1.5 rich-12.6.0 traittypes-0.2.1 voxelfuse-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IMPORTANTE\n",
        "Para el correcto funcionamiento de los import, es necesario eliminar \n",
        "la linea: \"from quad_mesh_simplify import simplify_mesh\" del \n",
        "archivo mesh.py.\n",
        "\"\"\"\n",
        "from voxelfuse.voxel_model import VoxelModel\n",
        "from voxelfuse.primitives import generateMaterials\n",
        "from voxelfuse.mesh import Mesh"
      ],
      "metadata": {
        "id": "z9gjlpIhITSn"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VoxToSTL(obj, filename):\n",
        "  if __name__=='__main__':\n",
        "    model = VoxelModel(obj, generateMaterials(4))  #4 is aluminium.\n",
        "    mesh = Mesh.fromVoxelModel(model)\n",
        "    mesh.export(f'{filename}.stl')"
      ],
      "metadata": {
        "id": "RLtSarArIdar"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VoxToSTL(x_val[k].reshape(32,32,32), 'broken')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-xdF4LvImY5",
        "outputId": "529587fb-8434-442e-c225-2fe264b0de32"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding exterior voxels: 100%|██████████| 22/22 [00:00<00:00, 711.85it/s]\n",
            "Meshing: 100%|██████████| 2070/2070 [00:00<00:00, 5946.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VoxToSTL((prediction[k] - x_val[k]).reshape(32,32,32), 'patch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0InnJVDIsY0",
        "outputId": "94b13360-059c-4451-fd26-24686e8ab4c0"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding exterior voxels: 100%|██████████| 8/8 [00:00<00:00, 1585.67it/s]\n",
            "Meshing: 100%|██████████| 168/168 [00:00<00:00, 5440.92it/s]\n"
          ]
        }
      ]
    }
  ]
}